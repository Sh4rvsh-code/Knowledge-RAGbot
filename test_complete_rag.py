#!/usr/bin/env python3
"""
Comprehensive End-to-End RAG Test
Tests the complete pipeline exactly as Streamlit app would use it
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd()))

def test_complete_rag_pipeline():
    """Test the complete RAG pipeline."""
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE RAG BOT END-TO-END TEST")
    print("=" * 80)
    
    from app.config import Settings
    from app.core.ingestion.extractors import ExtractorFactory
    from app.core.ingestion.chunker import RecursiveChunker
    from app.core.ingestion.embedder import get_embedder
    from app.core.ingestion.indexer import get_index_manager
    from app.core.retrieval.retriever import SemanticRetriever
    from app.core.llm.orchestrator import LLMOrchestrator
    from app.core.llm.remote_llm import get_llm
    from app.models.database import DatabaseManager, Document, Chunk
    import uuid
    import json
    
    # Initialize components
    settings = Settings()
    embedder = get_embedder()
    index_manager = get_index_manager(dimension=384)
    db_manager = DatabaseManager(settings.database_url)
    retriever = SemanticRetriever(top_k=5, similarity_threshold=0.3)
    llm = get_llm()
    orchestrator = LLMOrchestrator(llm)
    
    print(f"\nâœ“ System Initialized")
    print(f"  LLM: {type(llm).__name__}")
    print(f"  FAISS vectors: {index_manager.index.ntotal}")
    
    # Test queries on existing documents
    test_queries = [
        ("What is Python?", "test_document.txt"),
        ("What are Python's key features?", "test_document.txt"),
        ("What can Python be used for?", "test_document.txt"),
    ]
    
    print("\n" + "-" * 80)
    print("TESTING QUERIES ON EXISTING DOCUMENTS")
    print("-" * 80)
    
    for i, (query, expected_file) in enumerate(test_queries, 1):
        print(f"\n[Test {i}] Query: \"{query}\"")
        print(f"Expected file: {expected_file}")
        
        # Retrieve
        results = retriever.search(query, top_k=3, min_score=0.3)
        
        if not results:
            print(f"  âŒ No results retrieved!")
            continue
        
        print(f"  âœ“ Retrieved {len(results)} chunks:")
        for j, result in enumerate(results, 1):
            match = "âœ“" if result['filename'] == expected_file else "âœ—"
            print(f"    [{j}] {match} {result['filename']} (score: {result['score']:.3f})")
            print(f"        {result['chunk_text'][:80]}...")
        
        # Generate answer
        answer = orchestrator.answer_question(query, results, max_tokens=150)
        print(f"\n  ğŸ“ Answer:")
        print(f"     {answer}")
        
        # Check if answer seems relevant
        if len(answer) > 20 and any(word in answer.lower() for word in ['python', 'programming', 'language']):
            print(f"  âœ… Answer appears relevant!")
        else:
            print(f"  âš ï¸  Answer may not be relevant")
    
    print("\n" + "=" * 80)
    print("END-TO-END TEST COMPLETE")
    print("=" * 80)
    
    # Summary
    with db_manager.get_session() as session:
        doc_count = session.query(Document).count()
        chunk_count = session.query(Chunk).count()
    
    print(f"\nğŸ“Š System Status:")
    print(f"   Documents: {doc_count}")
    print(f"   Chunks in DB: {chunk_count}")
    print(f"   Vectors in FAISS: {index_manager.index.ntotal}")
    print(f"   Status: {'âœ… Synced' if chunk_count == index_manager.index.ntotal else 'âš ï¸ Out of sync'}")
    
    print("\nğŸ‰ RAG Bot is working correctly!")
    print("   âœ“ Document retrieval working")
    print("   âœ“ LLM generating answers")
    print("   âœ“ Full pipeline operational")

if __name__ == "__main__":
    test_complete_rag_pipeline()
